{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55a9111d-4b61-46bd-b4b7-4a1862260eb3",
   "metadata": {},
   "source": [
    "# Studying within hemisphere dynamics over learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2478a36b-cc2f-44d9-8013-fc42abe8eaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\catherinewang\\AppData\\Local\\Programs\\Python\\Python38\\python.exe\n",
      "C:\\Anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e2607b-7b13-4235-b924-bc3d7c59d586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:\\scripts\\Imaging analysis\")\n",
    "sys.path.append(\"C:\\scripts\\Imaging analysis\\src\")\n",
    "sys.path.append(\"Users/catherinewang/Desktop/Imaging analysis/2pimagingAnalysis/src\")\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import matplotlib.pyplot as plt\n",
    "from alm_2p import session\n",
    "from activityMode import Mode\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import stats\n",
    "from numpy.linalg import norm\n",
    "# from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "agg_mice_paths = [[r'F:\\data\\BAYLORCW032\\python\\2023_10_08',\n",
    "          r'F:\\data\\BAYLORCW032\\python\\2023_10_16',\n",
    "          r'F:\\data\\BAYLORCW032\\python\\2023_10_25',\n",
    "          r'H:\\data\\matched_topic_params\\CW32_table'],\n",
    "         \n",
    "        [ r'F:\\data\\BAYLORCW034\\python\\2023_10_12',\n",
    "              r'F:\\data\\BAYLORCW034\\python\\2023_10_22',\n",
    "              r'F:\\data\\BAYLORCW034\\python\\2023_10_27',\n",
    "              r'H:\\data\\matched_topic_params\\CW34_table'],\n",
    "\n",
    "        [r'F:\\data\\BAYLORCW036\\python\\2023_10_09',\n",
    "            r'F:\\data\\BAYLORCW036\\python\\2023_10_19',\n",
    "            r'F:\\data\\BAYLORCW036\\python\\2023_10_30',\n",
    "            r'H:\\data\\matched_topic_params\\CW36_table'],\n",
    "    \n",
    "        [r'F:\\data\\BAYLORCW035\\python\\2023_10_26',\n",
    "            r'F:\\data\\BAYLORCW035\\python\\2023_12_07',\n",
    "            r'F:\\data\\BAYLORCW035\\python\\2023_12_15',\n",
    "            r'H:\\data\\matched_topic_params\\CW35_table'],\n",
    "     \n",
    "        [r'F:\\data\\BAYLORCW037\\python\\2023_11_21',\n",
    "             r'F:\\data\\BAYLORCW037\\python\\2023_12_08',\n",
    "             r'F:\\data\\BAYLORCW037\\python\\2023_12_15',\n",
    "             r'H:\\data\\matched_topic_params\\CW37_table'],\n",
    "        \n",
    "        [r'H:\\data\\BAYLORCW044\\python\\2024_05_22',\n",
    "              r'H:\\data\\BAYLORCW044\\python\\2024_06_06',\n",
    "            r'H:\\data\\BAYLORCW044\\python\\2024_06_19',\n",
    "            r'H:\\data\\matched_topic_params\\CW44_FOV1_table'],\n",
    "        \n",
    "        [r'H:\\data\\BAYLORCW044\\python\\2024_05_23',\n",
    "            r'H:\\data\\BAYLORCW044\\python\\2024_06_04',\n",
    "            r'H:\\data\\BAYLORCW044\\python\\2024_06_18',\n",
    "            r'H:\\data\\matched_topic_params\\CW44_FOV2_table'],\n",
    "        \n",
    "        # [r'H:\\data\\BAYLORCW046\\python\\2024_05_29',\n",
    "        #     r'H:\\data\\BAYLORCW046\\python\\2024_06_07',\n",
    "        #     r'H:\\data\\BAYLORCW046\\python\\2024_06_24',\n",
    "        #     r'H:\\data\\matched_topic_params\\CW46_FOV1_table'],\n",
    "        \n",
    "        [r'H:\\data\\BAYLORCW046\\python\\2024_05_30',\n",
    "            r'H:\\data\\BAYLORCW046\\python\\2024_06_10',\n",
    "            r'H:\\data\\BAYLORCW046\\python\\2024_06_27',\n",
    "            r'H:\\data\\matched_topic_params\\CW46_FOV2_table'],\n",
    "        \n",
    "        [r'H:\\data\\BAYLORCW046\\python\\2024_05_31',\n",
    "            r'H:\\data\\BAYLORCW046\\python\\2024_06_11',\n",
    "            r'H:\\data\\BAYLORCW046\\python\\2024_06_26',\n",
    "            r'H:\\data\\matched_topic_params\\CW46_FOV3_table']\n",
    "                            \n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb09e1-9383-4677-bd70-ab1e410d412b",
   "metadata": {},
   "source": [
    "Using this notebook to organize the results of analysis, with code included so that the subprocess is clear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a39d53-fceb-46d0-83a3-5503e03329cd",
   "metadata": {},
   "source": [
    "## Are there multiple CDs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f3cd42-e8a1-4726-84c7-8024e347cfbc",
   "metadata": {},
   "source": [
    "Show that CDs are different in learning session - show that the decoding accuracy of CD's calculated in one set of trials is a lot higher than in another set of trials\n",
    "\n",
    "First, focus on showing this solely in the learning stage:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9af2f65-33c4-4342-9ff8-526e15f94153",
   "metadata": {},
   "source": [
    "Asking, are within cluster neurons / trials better at decoding within trials vs without trials?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf51d74-ddc7-4ec8-9868-4fd185778bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_learning_wi_decodingaccs = []\n",
    "all_learning_wo_decodingaccs = []\n",
    "\n",
    "all_expert_wi_decodingaccs = []\n",
    "all_expert_wo_decodingaccs = []\n",
    "\n",
    "\n",
    "for paths in agg_mice_paths:\n",
    "    clusters = pd.read_pickle(paths[3] + 'last_1')\n",
    "    trialparams = np.mean(clusters.trial_params.to_numpy())\n",
    "    num_clusters = len(trialparams.columns)\n",
    "\n",
    "    learning = trialparams.loc[idx['learning', :]]\n",
    "    learning_normalized = pd.DataFrame(normalize(learning, norm='l1'), columns=learning.columns)#, index=learning.index)\n",
    "    \n",
    "    expert = trialparams.loc[idx['expert', :]]\n",
    "    expert_normalized = pd.DataFrame(normalize(expert, norm='l1'), columns=expert.columns)#, index=expert.index)\n",
    "    \n",
    "    neuronparams = np.mean(clusters.components.to_numpy()).T\n",
    "    neurons_norm = pd.DataFrame(normalize(neuronparams, norm='l1'), columns=neuronparams.columns, index=neuronparams.index)\n",
    "    neurons_norm_arr = neurons_norm.to_numpy()\n",
    "        \n",
    "    learning_wi_decodingaccs = []\n",
    "    learning_wo_decodingaccs = []\n",
    "    \n",
    "    expert_wi_decodingaccs = []\n",
    "    expert_wo_decodingaccs = []\n",
    "\n",
    "    for cl in range(num_clusters):\n",
    "        \n",
    "        ## LEARNING ## \n",
    "        \n",
    "        max_neurons_norm_arr = np.where(np.argmax(neurons_norm_arr, axis=1) == cl)[0]\n",
    "        cluster_trials_all_idx = learning_normalized.index[learning_normalized['topic_{}'.format(cl)] > 1 / num_clusters].to_numpy()\n",
    "        # cluster_trials_all_idx = np.where(np.argmax(learning_normalized, axis=1) == cluster)[0]\n",
    "        all_acc_learning = []\n",
    "        for _ in range(5):\n",
    "\n",
    "            s1 = Mode(paths[1], use_reg = True, triple=True, baseline_normalization=\"median_zscore\",\n",
    "                      filter_good_neurons=neurons_norm.index,\n",
    "                        cluster_neurons=max_neurons_norm_arr,\n",
    "                          i_good = cluster_trials_all_idx,\n",
    "                          lda_cluster=True)\n",
    "                          # train_test_trials = cluster_trials_all_idx)\n",
    "        \n",
    "            try:\n",
    "                _, _, db, acc_learning = s1.decision_boundary(mode_input='choice', persistence=False, ctl=True)\n",
    "            except np.linalg.LinAlgError:\n",
    "                all_acc_learning += [0]\n",
    "                continue\n",
    "            all_acc_learning += [np.mean(acc_learning)]\n",
    "        \n",
    "        learning_wi_decodingaccs += [np.mean(all_acc_learning)]\n",
    "        \n",
    "        # wo_trials = [i for i in learning_normalized.index if i not in cluster_trials_all_idx]\n",
    "        wo_neurons = np.array([i for i in range(neurons_norm_arr.shape[0]) if i not in max_neurons_norm_arr])\n",
    "\n",
    "        all_acc_learning = []\n",
    "        for _ in range(5):\n",
    "\n",
    "            s1 = Mode(paths[1], use_reg = True, triple=True, baseline_normalization=\"median_zscore\",\n",
    "                      filter_good_neurons=neurons_norm.index,\n",
    "                        cluster_neurons=wo_neurons,\n",
    "                          i_good = cluster_trials_all_idx,\n",
    "                          lda_cluster=True)\n",
    "                          # train_test_trials = cluster_trials_all_idx)\n",
    "\n",
    "            try:\n",
    "                _, _, db, acc_learning = s1.decision_boundary(mode_input='choice', persistence=False, ctl=True)\n",
    "            except np.linalg.LinAlgError:\n",
    "                all_acc_learning += [0]\n",
    "                continue\n",
    "            all_acc_learning += [np.mean(acc_learning)]\n",
    "        \n",
    "        learning_wo_decodingaccs += [np.mean(all_acc_learning)]\n",
    "        \n",
    "        ## EXPERT ## \n",
    "        \n",
    "        cluster_trials_all_idx = expert_normalized.index[expert_normalized['topic_{}'.format(cl)] > 1 / num_clusters].to_numpy()\n",
    "        # cluster_trials_all_idx = np.where(np.argmax(learning_normalized, axis=1) == cluster)[0]\n",
    "        all_acc_learning = []\n",
    "        for _ in range(5):\n",
    "\n",
    "            s1 = Mode(paths[2], use_reg = True, triple=True, baseline_normalization=\"median_zscore\",\n",
    "                      filter_good_neurons=neurons_norm.index,\n",
    "                        cluster_neurons=max_neurons_norm_arr,\n",
    "                          i_good = cluster_trials_all_idx,\n",
    "                          \n",
    "                          lda_cluster=True)\n",
    "                          # train_test_trials = cluster_trials_all_idx)\n",
    "        \n",
    "            try:\n",
    "                _, _, db, acc_learning = s1.decision_boundary(mode_input='choice', persistence=False, ctl=True)\n",
    "            except np.linalg.LinAlgError:\n",
    "                all_acc_learning += [0]\n",
    "                continue\n",
    "            all_acc_learning += [np.mean(acc_learning)]\n",
    "        \n",
    "        expert_wi_decodingaccs += [np.mean(all_acc_learning)]\n",
    "        \n",
    "        # wo_trials = [i for i in learning_normalized.index if i not in cluster_trials_all_idx]\n",
    "        wo_neurons = np.array([i for i in range(neurons_norm_arr.shape[0]) if i not in max_neurons_norm_arr])\n",
    "\n",
    "        all_acc_learning = []\n",
    "        for _ in range(5):\n",
    "\n",
    "            s1 = Mode(paths[2], use_reg = True, triple=True, baseline_normalization=\"median_zscore\",\n",
    "                      filter_good_neurons=neurons_norm.index,\n",
    "                        cluster_neurons=wo_neurons,\n",
    "                          i_good = cluster_trials_all_idx,\n",
    "                          lda_cluster=True)\n",
    "                          # train_test_trials = cluster_trials_all_idx)\n",
    "\n",
    "            try:\n",
    "                _, _, db, acc_learning = s1.decision_boundary(mode_input='choice', persistence=False, ctl=True)\n",
    "            except np.linalg.LinAlgError:\n",
    "                all_acc_learning += [0]\n",
    "                continue\n",
    "            all_acc_learning += [np.mean(acc_learning)]\n",
    "        \n",
    "        expert_wo_decodingaccs += [np.mean(all_acc_learning)]\n",
    "        \n",
    "        \n",
    "        \n",
    "    all_learning_wi_decodingaccs += [learning_wi_decodingaccs]\n",
    "    all_learning_wo_decodingaccs += [learning_wo_decodingaccs]\n",
    "    \n",
    "    all_expert_wi_decodingaccs += [expert_wi_decodingaccs]\n",
    "    all_expert_wo_decodingaccs += [expert_wo_decodingaccs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0385cb-453c-4293-91d4-d0a2cf26a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Look at cluster 1 neurons decoding on cluster 1 trials vs other cluster trials learning FOV\n",
    "\n",
    "wi_decodingaccs = []\n",
    "wo_decodingaccs = []\n",
    "for cl in range(num_clusters):\n",
    "    \n",
    "    max_neurons_norm_arr = np.where(np.argmax(neurons_norm_arr, axis=1) == cl)[0]\n",
    "    cluster_trials_all_idx = learning_normalized.index[learning_normalized['topic_{}'.format(cl)] > 0.25].to_numpy()\n",
    "    # cluster_trials_all_idx = np.where(np.argmax(learning_normalized, axis=1) == cluster)[0]\n",
    "    all_acc_learning = []\n",
    "    for _ in range(5):\n",
    "\n",
    "        s1 = Mode(learningpath, use_reg = True, triple=True, baseline_normalization=\"median_zscore\",\n",
    "                  filter_good_neurons=neurons_norm.index,\n",
    "                    cluster_neurons=max_neurons_norm_arr,\n",
    "                      i_good = cluster_trials_all_idx,\n",
    "                      \n",
    "                      lda_cluster=True)\n",
    "                      # train_test_trials = cluster_trials_all_idx)\n",
    "    \n",
    "        _, _, db, acc_learning = s1.decision_boundary(mode_input='choice', persistence=False)\n",
    "        all_acc_learning += [np.mean(acc_learning)]\n",
    "    \n",
    "    wi_decodingaccs += [np.mean(all_acc_learning)]\n",
    "    \n",
    "    wo_trials = [i for i in learning_normalized.index if i not in cluster_trials_all_idx]\n",
    "    \n",
    "    all_acc_learning = []\n",
    "    for _ in range(5):\n",
    "\n",
    "        s1 = Mode(learningpath, use_reg = True, triple=True, baseline_normalization=\"median_zscore\",\n",
    "                  filter_good_neurons=neurons_norm.index,\n",
    "                    cluster_neurons=max_neurons_norm_arr,\n",
    "                      i_good = wo_trials,\n",
    "                      lda_cluster=True)\n",
    "                      # train_test_trials = cluster_trials_all_idx)\n",
    "\n",
    "        _, _, db, acc_learning = s1.decision_boundary(mode_input='choice', persistence=False)\n",
    "        all_acc_learning += [np.mean(acc_learning)]\n",
    "    \n",
    "    \n",
    "    wo_decodingaccs += [np.mean(all_acc_learning)]\n",
    "\n",
    "#Plot\n",
    "\n",
    "plt.bar(np.arange(num_clusters)-0.2, wi_decodingaccs, 0.4, label='within-cluster')\n",
    "plt.bar(np.arange(num_clusters)+0.2, wo_decodingaccs, 0.4, label='without cluster')\n",
    "\n",
    "plt.ylabel('Decoding accuracy')\n",
    "plt.xticks([0,1,2,3])\n",
    "plt.xlabel('Cluster')\n",
    "plt.legend()\n",
    "plt.ylim(bottom=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f676934-1842-4d57-a262-104b4247e1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dda7d-a779-466d-bce6-29ee13e939dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aaf80f-95a7-4538-aed6-1657978a5da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61c425d2-1b60-41e7-902d-624f9e756254",
   "metadata": {},
   "source": [
    "## Are CDs pruned over learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fba355-9c22-4fda-be29-c00f24d878f3",
   "metadata": {},
   "source": [
    "Need to show that the decoding accuracy of certain CDs in the learning stage do not decode well in the expert stage, whereas others do\n",
    "\n",
    "Complementary: show that the angles of CDs are more or less aligned with the angle of the final CD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2979b294-f599-4961-bf50-e065d7df810f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae6a3f-a43a-4489-b440-570152f35ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9569c3a5-1d1f-4bbf-8a70-a7e7f90f57c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5408bb-7ce6-40df-af46-c35c8b7b37b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16a8f820-4e27-4120-b3e0-b5816b23946e",
   "metadata": {},
   "source": [
    "## Is there any early lick CD?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b4bd82-5d22-4997-880c-cdaa41904a4c",
   "metadata": {},
   "source": [
    "How does this lick CD align with future choice CDs? use decoding accuracy as a measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb7a49-9557-4260-9ef6-9215e94e428c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6371ebc8-fe83-48bb-b118-3e718bb72437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e7e55-0222-498e-9f48-dc5c9601a04c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720914bc-2a2a-436a-904b-cb7e5ab33d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c29c93-8e6a-4dca-b111-c19ac2bb9e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "417754bf-2156-4a6a-9bc6-e5219394e31f",
   "metadata": {},
   "source": [
    "## Which CD is chosen? \n",
    "Related to robustness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df7542-4697-4037-aad7-0e66a195d71d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
